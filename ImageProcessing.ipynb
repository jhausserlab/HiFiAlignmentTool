{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Files and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import data, io\n",
    "from skimage.registration import phase_cross_correlation # new form of register_translation\n",
    "from scipy.ndimage import shift\n",
    "import napari\n",
    "import glob\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "from aicsimageio import AICSImage\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new size wanted 17 11\n",
      "a shape: 2 5\n",
      "b shape: 5 8\n",
      "a difference 15 6\n",
      "b difference 12 3\n",
      "What needs to be added on the edges: 7.5 3.0\n",
      "new_a (17, 11)\n",
      "new_b (17, 11)\n"
     ]
    }
   ],
   "source": [
    "x = 17\n",
    "y = 11\n",
    "\n",
    "a = np.ones((2,5), dtype = np.int16)\n",
    "b = np.pad(a,(1,2),'constant')\n",
    "\n",
    "xa = np.shape(a)[0]; xb = np.shape(b)[0]\n",
    "ya = np.shape(a)[1]; yb = np.shape(b)[1]\n",
    "\n",
    "print('new size wanted',x,y)\n",
    "print('a shape:',xa,ya); print('b shape:',xb,yb)\n",
    "\n",
    "xa_dif = x-xa; ya_dif = y-ya\n",
    "print('a difference',xa_dif,ya_dif)\n",
    "xb_dif = x-xb; yb_dif = y-yb\n",
    "print('b difference',xb_dif,yb_dif)\n",
    "print('What needs to be added on the edges:',(xa_dif)/2,(ya_dif)/2)\n",
    "new_a = np.pad(a,((int(np.floor((xa_dif)/2)), int(np.ceil((xa_dif)/2)))\n",
    "               ,(int(np.floor((ya_dif)/2)), int(np.ceil((ya_dif)/2)))),'constant')\n",
    "new_b = np.pad(b,((int(np.floor((xb_dif)/2)), int(np.ceil((xb_dif)/2)))\n",
    "               ,(int(np.floor((yb_dif)/2)), int(np.ceil((yb_dif)/2)))),'constant')\n",
    "\n",
    "print('new_a',np.shape(new_a))\n",
    "print('new_b',np.shape(new_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[4. 4. 4.]\n",
      "  [4. 4. 4.]]] (3, 2, 3)\n",
      "[[[4. 4. 4.]\n",
      "  [4. 4. 4.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]]] (3, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((1,2,3))\n",
    "a = 4*a\n",
    "b = np.ones((2,2,3))\n",
    "\n",
    "c = np.concatenate((b,a),axis=0)\n",
    "print(c, np.shape(c))\n",
    "\n",
    "d = np.concatenate((np.reshape(c[-1],(1,np.shape(c)[1],np.shape(c)[2])),c[:-1]), axis = 0)\n",
    "print(d, np.shape(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_for_approval():\n",
    "    hasApproval = False\n",
    "\n",
    "    while not hasApproval:\n",
    "        user_input = input('Continue with image processing for the above files? (Yes/No): ').strip().lower()\n",
    "\n",
    "        if user_input == 'yes' or user_input == 'y':\n",
    "            hasApproval = True\n",
    "        elif user_input == 'no' or user_input == 'n':\n",
    "            print('Terminating image processing.')\n",
    "            exit()\n",
    "        else:\n",
    "            print('Please enter a valid option.')\n",
    "    \n",
    "def get_tiffiles(source):\n",
    "    return glob.glob(source + '/**/*.tif', recursive=True)\n",
    "\n",
    "def list_files(source, files):\n",
    "    file_names = '\\n'.join(files)\n",
    "    file_list = f'''Found the following image files in {source}: \\n\\n{file_names}\\n'''\n",
    "    print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_shape(source):\n",
    "    \n",
    "    filepath = glob.glob(source + '/**/*.txt', recursive=True)\n",
    "    print ('Getting max dimensions with: ',filepath)\n",
    "    file = open(filepath[0],'r')\n",
    "    images_shape = file.read()\n",
    "    split = images_shape.split(';')\n",
    "    xmax = 0\n",
    "    ymax = 0\n",
    "    print(split)\n",
    "    #print('------------------------',xmax,ymax)\n",
    "    for i in range(len(split)-1):\n",
    "        frag = split[i].split(',')\n",
    "        xmax = max(xmax,int(frag[1]))\n",
    "        ymax = max(ymax,int(frag[2]))\n",
    "    print('(Xmax, Ymax) --------------- ',xmax,ymax)\n",
    "        \n",
    "    return xmax,ymax\n",
    "\n",
    "def pad_images(xmax, ymax, image):\n",
    "    #image must be of dimension X,Y so we input channels not the whole image C,X,Y\n",
    "    x_diff = xmax - np.shape(image)[0]\n",
    "    y_diff = ymax - np.shape(image)[1]\n",
    "\n",
    "    padded_image = np.pad(image,((int(np.floor((x_diff)/2)), int(np.ceil((x_diff)/2)))\n",
    "               ,(int(np.floor((y_diff)/2)), int(np.ceil((y_diff)/2)))),'constant')\n",
    "    return padded_image\n",
    "\n",
    "def align_images(source, dapi_target, processed_tif):\n",
    "\n",
    "    aligned_images = []\n",
    "\n",
    "    dapi_to_offset = processed_tif[-1]\n",
    "    print('dapi_target shape', np.shape(dapi_target))\n",
    "    print('dapi_to_offset shape', np.shape(dapi_to_offset))\n",
    "\n",
    "    xmax, ymax = get_max_shape(source)\n",
    "    print('Recalibrating image size to', xmax, ymax)\n",
    "    max_dapi_target = pad_images(xmax, ymax, dapi_target)\n",
    "    \n",
    "    #padding of dapi_to_offset, calling it max_processed_tif to keep variables low\n",
    "    max_processed_tif = pad_images(xmax, ymax, dapi_to_offset)\n",
    "\n",
    "    shifted, error, diffphase = phase_cross_correlation(max_dapi_target, max_processed_tif)\n",
    "    print(f\"Detected subpixel offset (y, x): {shifted}\")\n",
    "\n",
    "    for channel in range(np.shape(processed_tif)[0]):\n",
    "        max_processed_tif = pad_images(xmax, ymax, processed_tif[channel,:,:])\n",
    "        aligned_images.append(shift(max_processed_tif, shift=(shifted[0], shifted[1]), mode='constant'))\n",
    "        \n",
    "    print('transformed channels done, image is of size', np.shape(aligned_images))\n",
    "    return aligned_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reference(source, file, processed_tif0):\n",
    "    reference_image = []\n",
    "    #DAPI as first image\n",
    "    xmax, ymax = get_max_shape(source)\n",
    "    reference_image.append(pad_images(xmax, ymax, processed_tif0[-1]))\n",
    "    for channel in range(np.shape(processed_tif0)[0]-1):\n",
    "        reference_image.append(pad_images(xmax, ymax, processed_tif0[channel,:,:]))\n",
    "        \n",
    "    with tifffile.TiffWriter('./aligned/' + file[0].split()[0].split('/')[2].split('.')[0] + '_reference.tif',\n",
    "                                 bigtiff = True) as tif:\n",
    "        tif.save(reference_image)\n",
    "    print('Saved Reference Image: ', file[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aligned_images(source):\n",
    "    # source needs to be a str of where are the tif stored\n",
    "    files = get_tiffiles(source)\n",
    "    list_files(source,files)\n",
    "    \n",
    "    #ask_for_approval()\n",
    "\n",
    "    print ('Reference dapi is from:', files[0].split())\n",
    "    processed_tif0 = tifffile.imread(files[0].split())\n",
    "    dapi_target = processed_tif0[-1]\n",
    "    \n",
    "    #save_reference(source, files[0].split(), processed_tif0)\n",
    "    #Do not need processed_tif0 only dapi_target from it\n",
    "    del processed_tif0\n",
    "    gc.collect()\n",
    "    \n",
    "    #for file in files[1:]:\n",
    "    for file in files:\n",
    "        print('--- Aligning tif i:', file.split())\n",
    "        processed_tif = tifffile.imread(file.split())\n",
    "        print('Shape of image i is: ', np.shape(processed_tif))\n",
    "        align_tif = align_images(source, dapi_target, processed_tif)\n",
    "        print('Saving aligned image')\n",
    "        with tifffile.TiffWriter('./aligned/'+file.split()[0].split('/')[2].split('.')[0]+'_align.tif',\n",
    "                                 bigtiff = True) as tif:\n",
    "            tif.save(align_tif)\n",
    "    print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following image files in ./output: \n",
      "\n",
      "./output/align1_processed.tif\n",
      "./output/align2_processed.tif\n",
      "\n",
      "Reference dapi is from: ['./output/align1_processed.tif']\n",
      "--- Aligning tif i: ['./output/align1_processed.tif']\n",
      "Shape of image i is:  (5, 1825, 1995)\n",
      "dapi_target shape (1825, 1995)\n",
      "dapi_to_offset shape (1825, 1995)\n",
      "Getting max dimensions with:  ['./output/images_shape.txt']\n",
      "['10,1825,1995', '5,1825,1995', '5,1825,1995', '5,1825,1995', '']\n",
      "(Xmax, Ymax) ---------------  1825 1995\n",
      "Recalibrating image size to 1825 1995\n",
      "Detected subpixel offset (y, x): [0. 0.]\n",
      "transformed channels done, image is of size (5, 1825, 1995)\n",
      "Saving aligned image\n",
      "--- Aligning tif i: ['./output/align2_processed.tif']\n",
      "Shape of image i is:  (5, 1825, 1995)\n",
      "dapi_target shape (1825, 1995)\n",
      "dapi_to_offset shape (1825, 1995)\n",
      "Getting max dimensions with:  ['./output/images_shape.txt']\n",
      "['10,1825,1995', '5,1825,1995', '5,1825,1995', '5,1825,1995', '']\n",
      "(Xmax, Ymax) ---------------  1825 1995\n",
      "Recalibrating image size to 1825 1995\n",
      "Detected subpixel offset (y, x): [283. 416.]\n",
      "transformed channels done, image is of size (5, 1825, 1995)\n",
      "Saving aligned image\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "source = './output'\n",
    "get_aligned_images(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'align2_processed_align.tif'  # align1_processed_reference\n",
    "img = AICSImage('./aligned/'+fileName)\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer()\n",
    "    viewer.add_image(img.get_image_data(\"ZYX\", C=0, S=0, T=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
